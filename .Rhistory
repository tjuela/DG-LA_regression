#------ save feature file
write.csv(agg.features, file='features_test.csv')
View(agg.features)
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('datasets/OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
AverageVideoTimeDiffs = sum(AverageVideoTimeDiffs, na.rm = T)/sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features["AverageVideoTimeDiffsPerSubmission"]<-NA
agg.features$AverageVideoTimeDiffsPerSubmission <-(agg.features$AverageVideoTimeDiffs/
agg.features$countOfSubmissions)
agg.features[is.nan(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
b <- data.frame(c1=c(1, NaN, 2), c2=c(NaN, 2, 7))
b[is.na(b)] <- 0
b
b <- data.frame(c1=c(1, NaN, 2), c2=c(NaN, 2, 7))
b
b[is.na(b)] <- 0
b
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('datasets/OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
AverageVideoTimeDiffs = sum(AverageVideoTimeDiffs, na.rm = T)/sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features["AverageVideoTimeDiffsPerSubmission"]<-NA
agg.features$AverageVideoTimeDiffsPerSubmission <-(agg.features$AverageVideoTimeDiffs/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('datasets/OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
AverageVideoTimeDiffs = sum(AverageVideoTimeDiffs, na.rm = T)/sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features["AverageVideoTimeDiffsPerSubmission"]<-NA
agg.features$AverageVideoTimeDiffsPerSubmission <-(agg.features$AverageVideoTimeDiffs/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
#SAME FOR TEST
#------ read data frame
db=read.csv('datasets/OutputTable_test.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
AverageVideoTimeDiffs = sum(AverageVideoTimeDiffs, na.rm = T)/sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features$AverageVideoTimeDiffsPerSubmission <-(agg.features$AverageVideoTimeDiffs/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features_test.csv')
library(dplyr)
library(plyr) #ddply
library(caret)
library(doMC)
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID),]
#--- replace NA values with 0
db[is.na(db)]=0
#---- remove cases when there is no video or forum activity between two submissions
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.99)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
library(caret)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
"totalTime",
"totalVideoTime",
"AverageVideoTimeDiffs",
"countOfSubmissions",
"countOfThreadViews"
)
#for normalized features
fsNorm =c(
"VideoPerSubmission",
"ForumPerSubmission",
"ProblemID",
"totalTime",
"VideoTimePerSubmission",
"ThreadViewPerSubmission",
"countOfSubmissions",
"AverageVideoTimeDiffsPerSubmission"
)
#Control function
set.seed(123)
ctrl <- trainControl(method = "repeatedcv", repeats =3)
#glmnet
model4<- train(y=db.train$overalGradeDiff,
x = db.train[,fs],
method="glmnet",
trControl = ctrl,
tuneGrid = expand.grid(alpha = (1:10) * 0.1, lambda = (1:10) * 0.1),
metric = "RMSE",
preProc = c("center", "scale"))
model4
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
"totalTime",
"totalVideoTime",
# "AverageVideoTimeDiffs",
"countOfSubmissions",
"countOfThreadViews"
)
#glmnet
model4<- train(y=db.train$overalGradeDiff,
x = db.train[,fs],
method="glmnet",
trControl = ctrl,
tuneGrid = expand.grid(alpha = (1:10) * 0.1, lambda = (1:10) * 0.1),
metric = "RMSE",
preProc = c("center", "scale"))
model4
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
# "totalTime",
# "totalVideoTime",
"AverageVideoTimeDiffs",
"countOfSubmissions",
"countOfThreadViews"
)
#glmnet
model4<- train(y=db.train$overalGradeDiff,
x = db.train[,fs],
method="glmnet",
trControl = ctrl,
tuneGrid = expand.grid(alpha = (1:10) * 0.1, lambda = (1:10) * 0.1),
metric = "RMSE",
preProc = c("center", "scale"))
model4
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('datasets/OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
AverageVideoTimeDiffs = sum(AverageVideoTimeDiffs, na.rm = T)/sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features["AverageVideoTimeDiffsPerSubmission"]<-NA
agg.features$AverageVideoTimeDiffsPerSubmission <-(agg.features$AverageVideoTimeDiffs/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
#SAME FOR TEST
#------ read data frame
db=read.csv('datasets/OutputTable_test.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
AverageVideoTimeDiffs = sum(AverageVideoTimeDiffs, na.rm = T)/sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features$AverageVideoTimeDiffsPerSubmission <-(agg.features$AverageVideoTimeDiffs/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features_test.csv')
library(dplyr)
library(plyr) #ddply
library(caret)
library(doMC)
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID),]
#--- replace NA values with 0
db[is.na(db)]=0
#---- remove cases when there is no video or forum activity between two submissions
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.99)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
library(caret)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
# "totalTime",
# "totalVideoTime",
"AverageVideoTimeDiffs",
"countOfSubmissions",
"countOfThreadViews"
)
#for normalized features
fsNorm =c(
"VideoPerSubmission",
"ForumPerSubmission",
"ProblemID",
"totalTime",
# "AverageVideoTimeDiffsPerSubmission",
"VideoTimePerSubmission",
"ThreadViewPerSubmission",
"countOfSubmissions"
)
#Control function
set.seed(123)
ctrl <- trainControl(method = "repeatedcv", repeats =3)
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('datasets/OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
NoOfVidoesWatched = sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features["NoOfVidoesWatchedPerSubmission"]<-NA
agg.features$NoOfVidoesWatchedPerSubmission <-(agg.features$NoOfVidoesWatched/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
#SAME FOR TEST
#------ read data frame
db=read.csv('datasets/OutputTable_test.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
# dim(db)
# View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T),
NoOfVidoesWatched = sum(NoOfVidoesWatched, na.rm = T))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
agg.features["NoOfVidoesWatchedPerSubmission"]<-NA
agg.features$NoOfVidoesWatchedPerSubmission <-(agg.features$NoOfVidoesWatched/
agg.features$countOfSubmissions)
agg.features[is.na(agg.features)] <- 0
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features_test.csv')
library(dplyr)
library(plyr) #ddply
library(caret)
library(doMC)
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID),]
#--- replace NA values with 0
db[is.na(db)]=0
#---- remove cases when there is no video or forum activity between two submissions
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.99)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
library(caret)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
"totalTime",
"totalVideoTime",
"NoOfVidoesWatched",
"countOfSubmissions",
"countOfThreadViews"
)
#for normalized features
fsNorm =c(
"VideoPerSubmission",
"ForumPerSubmission",
"ProblemID",
"totalTime",
"NoOfVidoesWatchedPerSubmission",
"VideoTimePerSubmission",
"ThreadViewPerSubmission",
"countOfSubmissions"
)
#Control function
set.seed(123)
ctrl <- trainControl(method = "repeatedcv", repeats =3)
#glmnet
model4<- train(y=db.train$overalGradeDiff,
x = db.train[,fs],
method="glmnet",
trControl = ctrl,
tuneGrid = expand.grid(alpha = (1:10) * 0.1, lambda = (1:10) * 0.1),
metric = "RMSE",
preProc = c("center", "scale"))
model4
#glmnet
model4<- train(y=db.train$overalGradeDiff,
x = db.train[,fsNorm],
method="glmnet",
trControl = ctrl,
tuneGrid = expand.grid(alpha = (1:10) * 0.1, lambda = (1:10) * 0.1),
metric = "RMSE",
preProc = c("center", "scale"))
model4
test.pred = predict(model4, newdata=db.test[,fs]);
test.y = db.test$overalGradeDiff
test.pred = predict(model4, newdata=db.test[,fsNorm]);
test.y = db.test$overalGradeDiff
SS.total      <- sum((test.y - mean(test.y))^2)
SS.residual   <- sum((test.y - test.pred)^2)
SS.regression <- sum((test.pred - mean(test.y))^2)
SS.total <- (SS.regression+SS.residual)
# NOT the fraction of variability explained by the model
test.rsq <- 1 - SS.residual/SS.total
test.rsq
# fraction of variability explained by the model
SS.regression/SS.total
