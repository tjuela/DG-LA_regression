model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "logicBag",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "bridge",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method= "bridge",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('datasets/OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
dim(db)
View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T))
# countOfVideoAndForumEvents= (sum(NVideoEvents,na.rm = T)+sum(NForumEvents,na.rm = T)))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
#SAME FOR TEST
#------ read data frame
db=read.csv('datasets/OutputTable_test.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
dim(db)
View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
totalVideoTime= sum(DurationOfVideoActivity,na.rm=T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T),
countOfThreadViews = sum(NumberOfThreadViews, na.rm=T))
# countOfVideoAndForumEvents= (sum(NVideoEvents,na.rm = T)+sum(NForumEvents,na.rm = T)))
#-------normalize on submissions---------
agg.features["VideoPerSubmission"]<-NA
agg.features$VideoPerSubmission<-(agg.features$countOfVideoEvents/agg.features$countOfSubmissions)
agg.features["ForumPerSubmission"]<-NA
agg.features$ForumPerSubmission<-(agg.features$countOfForumEvents/agg.features$countOfSubmissions)
agg.features["VideoTimePerSubmission"]<-NA
agg.features$VideoTimePerSubmission<-(agg.features$totalVideoTime/agg.features$countOfSubmissions)
agg.features["ThreadViewPerSubmission"]<-NA
agg.features$ThreadViewPerSubmission<-(agg.features$countOfThreadViews/agg.features$countOfSubmissions)
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features_test.csv')
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID),]
#--- replace NA values with 0
db[is.na(db)]=0
#---- remove cases when there is no video or forum activity between two submissions
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
library(caret)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
"totalTime",
"totalVideoTime",
"countOfSubmissions",
"countOfThreadViews"
)
#for normalized features
fsNorm =c(
"VideoPerSubmission",
"ForumPerSubmission",
"ProblemID",
"totalTime",
"VideoTimePerSubmission",
"ThreadViewPerSubmission",
"countOfSubmissions"
)
model <- train(
y=db.train$overalGradeDiff,
x=db.train[,fs],
method = "lm"
)
model2 <- train(
y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method = "lm"
)
model2
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method= "bridge",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3
test.pred = predict(model, newdata=db.test[,fs]);
test.y = db.test$overalGradeDiff
SS.total      <- sum((test.y - mean(test.y))^2)
SS.residual   <- sum((test.y - test.pred)^2)
SS.regression <- sum((test.pred - mean(test.y))^2)
SS.total <- (SS.regression+SS.residual)
# NOT the fraction of variability explained by the model
test.rsq <- 1 - SS.residual/SS.total
test.rsq
# fraction of variability explained by the model
SS.regression/SS.total
SS.total
SS.regression
SS.residual
SS.total      <- sum((test.y - mean(test.y))^2)
SS.total
# fraction of variability explained by the model
SS.regression/SS.total
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "BstLm",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3
testDb=read.csv('features_test.csv', stringsAsFactors = F)
testDb$OveralGradeDiff=NULL
testDb[is.na(testDb)]=0
#---- use trained model to predict progress for test data
preds= predict(model3$finalModel, newdata=testDb[,fs]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
#------- submit the resulting file (classifier_results.csv) to kaggle
#------- report AUC in private score in your report
model3$finalModel
model3
test.pred = predict(model3, newdata=db.test[,fs]);
test.y = db.test$overalGradeDiff
SS.total      <- sum((test.y - mean(test.y))^2)
SS.residual   <- sum((test.y - test.pred)^2)
SS.regression <- sum((test.pred - mean(test.y))^2)
SS.total <- (SS.regression+SS.residual)
# NOT the fraction of variability explained by the model
test.rsq <- 1 - SS.residual/SS.total
test.rsq
# fraction of variability explained by the model
SS.regression/SS.total
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method= "cubist",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3
#---- use trained model to predict progress for test data
preds= predict(model3$finalModel, newdata=testDb[,fsNorm]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method= "enet",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "glmnet_h2o",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "glmnet",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3
model2 <- train(
y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method = "lm"
)
testDb=read.csv('features_test.csv', stringsAsFactors = F)
testDb$OveralGradeDiff=NULL
testDb[is.na(testDb)]=0
#---- use trained model to predict progress for test data
preds= predict(model2$finalModel, newdata=testDb[,fs]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
model2$finalModel
library(dplyr)
library(plyr) #ddply
library(caret)
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID),]
#--- replace NA values with 0
db[is.na(db)]=0
#---- remove cases when there is no video or forum activity between two submissions
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
library(caret)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
"totalTime",
"totalVideoTime",
"countOfSubmissions",
"countOfThreadViews"
)
#for normalized features
fsNorm =c(
"VideoPerSubmission",
"ForumPerSubmission",
"ProblemID",
"totalTime",
"VideoTimePerSubmission",
"ThreadViewPerSubmission",
"countOfSubmissions"
)
model <- train(
y=db.train$overalGradeDiff,
x=db.train[,fs],
method = "lm"
)
model2 <- train(
y=db.train$overalGradeDiff,
x=db.train[,fsNorm],
method = "lm"
)
#Control function
set.seed(123)
ctrl <- trainControl(method = "repeatedcv", repeats =3)
#svmLinear
svmLin <- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "svmLinear",
tuneLength=15,
trControl=ctrl,
metric ="RMSE",
preProc= c("center", "scale"))
testDb=read.csv('features_test.csv', stringsAsFactors = F)
testDb$OveralGradeDiff=NULL
testDb[is.na(testDb)]=0
#---- use trained model to predict progress for test data
preds= predict(model, newdata=testDb[,fs]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
metric="RMSE",
preProc= c("center", "scale"))
model3
testDb$OveralGradeDiff=NULL
testDb[is.na(testDb)]=0
#---- use trained model to predict progress for test data
preds= predict(model3$finalModel, newdata=testDb[,fs]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
testDb=read.csv('features_test.csv', stringsAsFactors = F)
testDb$OveralGradeDiff=NULL
testDb[is.na(testDb)]=0
#---- use trained model to predict progress for test data
preds= predict(model3, newdata=testDb[,fs]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
model3
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = grid,
metric="RMSE",
preProc= c("center", "scale"))
grid<-expand.grid(committees = c(15, 20, 25, 30),
+ neighbors = c(8, 9, 10))
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = grid,
metric="RMSE",
preProc= c("center", "scale"))
grid<-expand.grid(committees = c(15, 20, 25, 30), neighbors = c(8, 9, 10))
#Logic regression
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = grid,
metric="RMSE",
preProc= c("center", "scale"))
model3
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = expand.grid(committees = c(15, 20, 25, 30), neighbors = c(8, 9, 10)),
metric="RMSE",
preProc= c("center", "scale"))
warnings()
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = expand.grid(committees = c(15, 20, 25, 30), neighbors = c(1, 5, 9)),
metric="RMSE",
preProc= c("center", "scale"))
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID),]
#--- replace NA values with 0
db[is.na(db)]=0
#---- remove cases when there is no video or forum activity between two submissions
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.99)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
library(caret)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"ProblemID",
"totalTime",
"totalVideoTime",
"countOfSubmissions",
"countOfThreadViews"
)
#for normalized features
fsNorm =c(
"VideoPerSubmission",
"ForumPerSubmission",
"ProblemID",
"totalTime",
"VideoTimePerSubmission",
"ThreadViewPerSubmission",
"countOfSubmissions"
)
model3
#cubist
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = expand.grid(committees = c(23, 24, 25, 26,27), neighbors = c(7, 8, 9)),
metric="RMSE",
preProc= c("center", "scale"))
model3
#cubist
model3<- train(y=db.train$overalGradeDiff,
x=db.train[,fs],
method= "cubist",
trControl=ctrl,
tuneGrid = expand.grid(committees = c(21,22,23), neighbors = c(8,9)),
metric="RMSE",
preProc= c("center", "scale"))
model2
model3
testDb=read.csv('features_test.csv', stringsAsFactors = F)
testDb$OveralGradeDiff=NULL
testDb[is.na(testDb)]=0
#---- use trained model to predict progress for test data
preds= predict(model3, newdata=testDb[,fs]);
#========================================================================
#         step 2.1: prepare submission file for kaggle
#========================================================================
cl.Results=testDb[,c('ProblemID', 'UserID')]
cl.Results$overalGradeDiff=preds
cl.Results$uniqRowID= paste0(cl.Results$UserID,'_', cl.Results$ProblemID)
cl.Results=cl.Results[,c('uniqRowID','overalGradeDiff')]
table(cl.Results$overalGradeDiff)
#----- keep only rows which are listed in classifier_templtae.csv file
#----- this excludes first submissions and cases with no forum and video event in between two submissions
regression_template= read.csv('regression_template.csv', stringsAsFactors = F)
kaggleSubmission=merge(regression_template,cl.Results )
write.csv(kaggleSubmission,file='regression_results.csv', row.names = F)
