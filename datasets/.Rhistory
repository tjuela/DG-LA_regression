library(dplyr)
library(plyr) #ddply
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('Dataset and Scripts-20170113/OutputTable.csv', stringsAsFactors = F)
#------ read features extracted from train set, using your python script
db=read.csv('datasets/OutputTable.csv', stringsAsFactors = F)
#------ read features extracted from train set, using your python script
db=read.csv('datasets/OutputTable.csv', stringsAsFactors = F)
#------ read features extracted from train set, using your python script
db=read.csv('OutputTable.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
db= filter(db,NVideoAndForum>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
View(db)
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
dim(db)
View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
CountofSubmissions=length(SubmissionNumber),
countOfVideoandForumEvents= (sum(NVideoEvents,na.rm = T)+sum(NForumEvents,na.rm = T))  )
#------ remove cases with only one attempt
agg.features=filter(agg.features,CountofSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
db= filter(db,NVideoAndForum>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
View(db)
View(agg.features)
summary(db$CountofSubmissions)
db$CountofSubmissions
sapply(db$CountofSubmissions)
sapply(db$CountofSubmissions, FUN = mean)
count(db$CountofSubmissions)
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
# db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
# db= filter(db,NVideoAndForum>0)
db= filter(db,CountOfVideoAndForumEvents>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
# db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
# db= filter(db,NVideoAndForum>0)
db= filter(db,CountOfVideoandForumEvents>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
# db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
# db= filter(db,NVideoAndForum>0)
db= filter(db, countOfVideoandForumEvents>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
View(db)
count(db$overalGradeDiff)
plot(count(db$overalGradeDiff))
hist(count(db$overalGradeDiff))
hist(db$overalGradeDiff)
View(agg.features)
library(dplyr)
library(plyr) #ddply
#------ read data frame
db=read.csv('OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
dim(db)
View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countofSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T))
# countOfVideoAndForumEvents= (sum(NVideoEvents,na.rm = T)+sum(NForumEvents,na.rm = T)))
#------ remove cases with only one attempt
agg.features=filter(agg.features,CountofSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
library(dplyr)
library(plyr) #ddply
#========================================================================
#         step 1: train classifier
#========================================================================
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
# db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
# db= filter(db,NVideoAndForum>0)
db= filter(db, countOfForumEvents>0)
db= filter(db, countOfVideoEvents>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
# db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
# db= filter(db,NVideoAndForum>0)
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
count(db$totalTime)
db=read.csv('OutputTable.csv')
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
dim(db)
View(db)
#------- aggregate by UserID and ProblemID ---------
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countofSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T))
# countOfVideoAndForumEvents= (sum(NVideoEvents,na.rm = T)+sum(NForumEvents,na.rm = T)))
#------ remove cases with only one attempt
agg.features=filter(agg.features,CountofSubmissions>1); dim(agg.features)
length(unique(db$UserID))
agg.features=ddply(db, .(UserID,ProblemID), summarise,
overalGradeDiff=Grade[length(Grade)]-Grade[1],
countOfSubmissions=length(SubmissionNumber),
totalTime = sum(TimeSinceLast, na.rm = T),
countOfVideoEvents = sum(NVideoEvents,na.rm = T),
countOfForumEvents = sum(NForumEvents,na.rm = T))
# countOfVideoAndForumEvents= (sum(NVideoEvents,na.rm = T)+sum(NForumEvents,na.rm = T)))
#------ remove cases with only one attempt
agg.features=filter(agg.features,countOfSubmissions>1); dim(agg.features)
#------ save feature file
write.csv(agg.features, file='features.csv')
#------ read features extracted from train set, using your python script
db=read.csv('features.csv', stringsAsFactors = F)
#------ sort submissions
db=db[order(db$UserID,db$ProblemID,db$SubmissionNumber),]
#--- replace NA values with 0
db[is.na(db)]=0
#----- remove first submissions
db= filter(db,SubmissionNumber>0)
#---- remove cases when there is no video or forum activity between two submissions
# db$NVideoAndForum= db$NVideoEvents+db$NForumEvents
# db= filter(db,NVideoAndForum>0)
db= filter(db, countOfForumEvents + countOfVideoEvents>0)
#----- make a catgorical vribale, indicating if grade improved
db$improved = factor(ifelse(db$GradeDiff>0 ,'Yes', 'No' ))
table(db$improved)
# ----- (Optional) split your training data into train and test set. Use train set to build your classifier and try it on test data to check generalizability.
set.seed(1234)
tr.index= sample(nrow(db), nrow(db)*0.9)
db.train= db[tr.index,]
db.test = db[-tr.index,]
dim(db.train)
dim(db.test)
hist(db$totalTime)
model <- lm(db$overalGradeDiff~db$CountOfVideoEvents+db$CountOfForumEvents+db$totalTime)
model <- lm(db$overalGradeDiff~db$countOfVideoEvents+db$countOfForumEvents+db$totalTime)
model
plot(model)
summary(model)
model <- lm(overalGradeDiff~countOfVideoEvents+countOfForumEvents+totalTime, data=db.train)
plot(model)
preds = predict(model, newdata=db.test);
table(preds)
summary(table(preds))
plot(model)
model <- train(
overalGradeDiff~., data=db.train,
method = "lm"
)
library(caret)
model <- train(
overalGradeDiff~., data=db.train,
method = "lm"
)
fs = c(
"countOfVideoEvents",
"countOfForumEvents",
"totalTime"
)
model <- train(
overalGradeDiff~fs, data=db.train,
method = "lm"
)
model <- train(
y=overalGradeDifffs,
x=fs,
data=db.train,
method = "lm"
)
model <- train(
y=overalGradeDiffs,
x=fs,
data=db.train,
method = "lm"
)
model <- train(
y=overalGradeDiff,
x=fs,
data=db.train,
method = "lm"
)
model <- train(
y=db.train$overalGradeDiff,
x=db.train[,fs],
method = "lm"
)
model
plot(model)
plot(model$finalModel)
preds = predict(model, newdata=db.test);
table(preds)
fit.model(db.test)
model$pred
preds = predict(model, newdata=db.test[,fs]);
table(preds)
preds = predict(model, newdata=db.test[,fs]);
preds
preds[1]
preds[,1]
test.pred = predict(model, newdata=db.test[,fs]);
test.y = db.test$overalGradeDiff
test
test.pred - test.y
err.residual <- sum((test.y - test.pred)^2)
err.residual
test.pred = predict(model, newdata=db.test[,fs]);
test.y = db.test$overalGradeDiff
SS.total      <- sum((test.y - mean(test.y))^2)
SS.residual   <- sum((test.y - test.pred)^2)
SS.regression <- sum((test.pred - mean(test.y))^2)
SS.total <- (SS.regression+SS.residual)
# NOT the fraction of variability explained by the model
test.rsq <- 1 - SS.residual/SS.total
test.rsq
# fraction of variability explained by the model
SS.regression/SS.total
# NOT the fraction of variability explained by the model
test.rsq <- 1 - SS.residual/SS.total
test.rsq
SS.regression/SS.total
model
SS.residual
SS.residual/length(test.pred)
sqrt(SS.residual/length(test.pred))
